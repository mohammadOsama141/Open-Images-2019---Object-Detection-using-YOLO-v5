{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578486fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d6b3c",
   "metadata": {},
   "source": [
    "# Making data format for yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb86e683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of csv:  2505516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ClassName</th>\n",
       "      <th>ImagePath</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000048549557964</td>\n",
       "      <td>Building</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...</td>\n",
       "      <td>0.125312</td>\n",
       "      <td>0.464583</td>\n",
       "      <td>0.250625</td>\n",
       "      <td>0.600833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000048549557964</td>\n",
       "      <td>Building</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...</td>\n",
       "      <td>0.291563</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.138125</td>\n",
       "      <td>0.125833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000048549557964</td>\n",
       "      <td>Building</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...</td>\n",
       "      <td>0.564375</td>\n",
       "      <td>0.617916</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000048549557964</td>\n",
       "      <td>Building</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...</td>\n",
       "      <td>0.805312</td>\n",
       "      <td>0.559167</td>\n",
       "      <td>0.388125</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001c6c99f4a838a</td>\n",
       "      <td>Building</td>\n",
       "      <td>C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...</td>\n",
       "      <td>0.499688</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.982176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID ClassName  \\\n",
       "0  0000048549557964  Building   \n",
       "1  0000048549557964  Building   \n",
       "2  0000048549557964  Building   \n",
       "3  0000048549557964  Building   \n",
       "4  0001c6c99f4a838a  Building   \n",
       "\n",
       "                                           ImagePath  center_x  center_y  \\\n",
       "0  C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...  0.125312  0.464583   \n",
       "1  C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...  0.291563  0.614583   \n",
       "2  C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...  0.564375  0.617916   \n",
       "3  C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...  0.805312  0.559167   \n",
       "4  C:\\Users\\PC\\OneDrive\\Desktop\\cv assign3 data\\t...  0.499688  0.507974   \n",
       "\n",
       "      width    height  class_int  \n",
       "0  0.250625  0.600833          0  \n",
       "1  0.138125  0.125833          0  \n",
       "2  0.043750  0.070833          0  \n",
       "3  0.388125  0.370000          0  \n",
       "4  0.999375  0.982176          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scv_path = 'C:/Users/PC/OneDrive/Desktop/cv assign3 data/filtered_csv\\\\final_dfV2.csv' \n",
    "\n",
    "df = pd.read_csv(scv_path)\n",
    "\n",
    "print(\"shape of csv: \",df.shape[0]) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f84436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c04feeaf",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b67e2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:  2004412\n",
      "val data size:  501104\n"
     ]
    }
   ],
   "source": [
    "#this methid does not work because multiple instance of same image id \n",
    "#train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "#print(\"train data size: \",len(train_df))\n",
    "#print(\"val data size: \",len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6fb11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "E:\\Conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:  2005836\n",
      "val data size:  499680\n"
     ]
    }
   ],
   "source": [
    "#a GroupShuffleSplit instance\n",
    "splitter = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "\n",
    "# Splitting the dataframe based on groups formed by 'ImageID'\n",
    "train_inds, val_inds = next(splitter.split(df, groups=df['ImageID']))\n",
    "\n",
    "\n",
    "train_df = df.iloc[train_inds]\n",
    "val_df = df.iloc[val_inds]\n",
    "\n",
    "print(\"train data size: \",len(train_df))\n",
    "print(\"val data size: \",len(val_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb29451",
   "metadata": {},
   "source": [
    "### saving train and val csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd590ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "output_csv_path = 'C:\\\\Users\\\\PC\\\\OneDrive\\\\Desktop\\\\cv assign3 data\\\\filtered_csv\\\\train_df.csv'\n",
    "train_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "#val\n",
    "output_csv_path = 'C:\\\\Users\\\\PC\\\\OneDrive\\\\Desktop\\\\cv assign3 data\\\\filtered_csv\\\\val_df.csv'\n",
    "val_df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9706c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train csv:  2005836\n",
      "shape of val csv:  499680\n"
     ]
    }
   ],
   "source": [
    "#using saved csv\n",
    "scv_path = 'C:\\\\Users\\\\PC\\\\OneDrive\\\\Desktop\\\\cv assign3 data\\\\filtered_csv\\\\train_df.csv' \n",
    "train_df = pd.read_csv(scv_path)\n",
    "print(\"shape of train csv: \",train_df.shape[0])\n",
    "\n",
    "scv_path = 'C:\\\\Users\\\\PC\\\\OneDrive\\\\Desktop\\\\cv assign3 data\\\\filtered_csv\\\\val_df.csv' \n",
    "val_df = pd.read_csv(scv_path)\n",
    "print(\"shape of val csv: \",val_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ad0c3",
   "metadata": {},
   "source": [
    "### making annotations for format of yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f149c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_annotations(df, folder_path):\n",
    "    grouped = df.groupby('ImageID')\n",
    "\n",
    "    for name, group in grouped:\n",
    "        filepath = os.path.join(folder_path, name + '.txt')\n",
    "        with open(filepath, 'w') as file:\n",
    "            for _, row in group.iterrows():\n",
    "                class_id = row['class_int']\n",
    "                bbox = (row['center_x'], row['center_y'], row['width'], row['height'])\n",
    "                bbox_str = ' '.join([str(x) for x in bbox])\n",
    "                line = f\"{class_id} {bbox_str}\\n\"\n",
    "                file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dbf3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_annotations(train_df, 'C:/Users/PC/OneDrive/Desktop/cv assign3 data/yolo_annotations/train')\n",
    "write_annotations(val_df, 'C:/Users/PC/OneDrive/Desktop/cv assign3 data/yolo_annotations/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf8cbe",
   "metadata": {},
   "source": [
    "## setting up data folder according to yolo standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d11b23",
   "metadata": {},
   "source": [
    "### moving main directory images to train and test folders accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da856e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shifting images to train and val folders using their individual dataframes\n",
    "base_image_dir = 'C:\\\\Users\\\\PC\\\\OneDrive\\\\Desktop\\\\cv assign3 data\\\\trainsubset\\\\'\n",
    "\n",
    "#directories for train and val datasets\n",
    "train_dir = 'C:\\\\Users\\\\PC\\\\OneDrive\\\\Desktop\\\\cv assign3 data\\\\data\\\\images\\\\train\\\\'\n",
    "val_dir = 'C:\\\\Users\\\\PC\\\\OneDrive\\\\Desktop\\\\cv assign3 data\\\\data\\\\images\\\\val\\\\'\n",
    "\n",
    "#chexk for directories exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "#function to move images based on ImageID from dataframe to their directories\n",
    "def move_images(df, destination):\n",
    "    for image_id in df['ImageID']:\n",
    "        image_name = image_id + '.jpg'  \n",
    "        source_path = os.path.join(base_image_dir, image_name)\n",
    "        dest_path = os.path.join(destination, image_name)\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.move(source_path, dest_path)\n",
    "\n",
    "\n",
    "            \n",
    "move_images(train_df, train_dir)#moving train images\n",
    "move_images(val_df, val_dir)#moving val images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8327ed99",
   "metadata": {},
   "source": [
    "### making a list of all class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231f2a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few class names: ['Tortoise', 'Container', 'Magpie', 'Sea turtle', 'Football', 'Ambulance', 'Ladder', 'Toothbrush', 'Syringe', 'Sink']\n",
      "601\n"
     ]
    }
   ],
   "source": [
    "label_names_csv_path = 'C:/Users/PC/OneDrive/Desktop/cv assign3 data/class-names-boxable.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "try:\n",
    "    label_names_df = pd.read_csv(label_names_csv_path, header=None)\n",
    "    # Assuming the second column contains the class names\n",
    "    class_names = label_names_df.iloc[:, 1].tolist()\n",
    "    # Display the first few class names for verification\n",
    "    print(\"First few class names:\", class_names[:10])\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while reading the file:\", e)\n",
    "\n",
    "#print(class_names) #prints a lot of classes so good\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13d97e",
   "metadata": {},
   "source": [
    "### making yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935cf66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data_yaml = {\n",
    "    'train': 'C:/Users/PC/OneDrive/Desktop/cv assign3 data/data/images/train',\n",
    "    'val': 'C:/Users/PC/OneDrive/Desktop/cv assign3 data/data/images/val',\n",
    "    'nc': len(class_names),\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "with open('dataset.yaml', 'w') as file:\n",
    "    yaml.dump(data_yaml, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e4fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fbd991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51dec7b9",
   "metadata": {},
   "source": [
    "## setting up yolo v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58011e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\CV LAB\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for gitpython>=3.1.30 from https://files.pythonhosted.org/packages/8d/c4/82b858fb6483dfb5e338123c154d19c043305b01726a67d89532b8f8f01b/GitPython-3.1.40-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 6)) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 7)) (1.25.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 8)) (4.8.1.78)\n",
      "Requirement already satisfied: Pillow>=10.0.1 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 9)) (10.0.1)\n",
      "Requirement already satisfied: psutil in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 10)) (5.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
      "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 15)) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 16)) (0.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
      "Collecting ultralytics>=8.0.147 (from -r requirements.txt (line 18))\n",
      "  Obtaining dependency information for ultralytics>=8.0.147 from https://files.pythonhosted.org/packages/35/6b/26ef27d9fac7448d035028b730f4b4f84a382c40a806cda26e077122d6d4/ultralytics-8.0.218-py3-none-any.whl.metadata\n",
      "  Downloading ultralytics-8.0.218-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 27)) (2.1.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in e:\\conda\\lib\\site-packages (from -r requirements.txt (line 42)) (68.0.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\conda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\conda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\conda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\conda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\conda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\conda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\conda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\conda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\conda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.5.7)\n",
      "Requirement already satisfied: filelock in e:\\conda\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in e:\\conda\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.7.1)\n",
      "Requirement already satisfied: sympy in e:\\conda\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1)\n",
      "Requirement already satisfied: networkx in e:\\conda\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1)\n",
      "Requirement already satisfied: jinja2 in e:\\conda\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.10.0)\n",
      "Requirement already satisfied: colorama in e:\\conda\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: py-cpuinfo in e:\\conda\\lib\\site-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (9.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\conda\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\conda\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in e:\\conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\conda\\lib\\site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\conda\\lib\\site-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
      "Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "   ---------------------------------------- 0.0/190.6 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/190.6 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 30.7/190.6 kB 660.6 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 41.0/190.6 kB 393.8 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 61.4/190.6 kB 469.7 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 61.4/190.6 kB 469.7 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 61.4/190.6 kB 469.7 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 71.7/190.6 kB 231.0 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 102.4/190.6 kB 281.0 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 143.4/190.6 kB 355.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 190.6/190.6 kB 427.3 kB/s eta 0:00:00\n",
      "Downloading ultralytics-8.0.218-py3-none-any.whl (645 kB)\n",
      "   ---------------------------------------- 0.0/645.8 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/645.8 kB 1.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 122.9/645.8 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 204.8/645.8 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 235.5/645.8 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 235.5/645.8 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 235.5/645.8 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------- --------------------- 286.7/645.8 kB 930.9 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 368.6/645.8 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 460.8/645.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 512.0/645.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 512.0/645.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 512.0/645.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------- ------ 542.7/645.8 kB 896.4 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 624.6/645.8 kB 958.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 645.8/645.8 kB 968.9 kB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.7/62.7 kB 3.3 MB/s eta 0:00:00\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, gitdb, thop, gitpython, ultralytics\n",
      "Successfully installed gitdb-4.0.11 gitpython-3.1.40 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts ultralytics.exe and yolo.exe are installed in 'C:\\Users\\PC\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "#already done\n",
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4514e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7b4a9ff",
   "metadata": {},
   "source": [
    "## Running training script - yolov5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f46542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27401b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/train.py --img 256 --batch 16 --epochs 50 --data dataset.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec05f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
